# Example demonstrating parallel result collection strategies
# This shows how to handle multiple processors feeding into one processor

strategy: work_queue
failure_strategy: fail_fast
executor_options:
  max_concurrency: 4

processors:
  - id: input_text
    type: local
    processor: change_text_case_upper
    depends_on: []

  # Two processors that run in parallel on the same input
  - id: token_counter
    type: local
    processor: token_counter
    depends_on: [input_text]

  - id: word_frequency
    type: local
    processor: word_frequency_analyzer
    depends_on: [input_text]

  # Result collector that combines outputs from parallel processors
  - id: merge_results
    type: local
    processor: result_collector
    collection_strategy:
      type: merge_metadata
      primary_source: "token_counter"
      metadata_sources: ["word_frequency"]
    depends_on: [token_counter, word_frequency]

  # Final processor that uses the merged results
  - id: final_processor
    type: local
    processor: prefix_suffix_adder
    options:
      prefix: "Analysis: "
      suffix: " [Complete]"
    depends_on: [merge_results]

# Flow demonstration:
# input_text -> [token_counter, word_frequency] -> merge_results -> final_processor
#
# The merge_results processor uses the merge_metadata collection strategy:
# - Primary payload comes from token_counter
# - word_frequency output is added as metadata
# - This ensures deterministic behavior instead of race conditions
