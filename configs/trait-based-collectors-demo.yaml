# ============================================================================
# The DAGwood - Trait-Based Collectors Demo Configuration
# ============================================================================
# This configuration demonstrates the new trait-based collector approach
# implementing ADR-12 (Processor Intent Declaration and Hybrid Execution Model)
#
# Key Features Showcased:
# - Explicit collector processors with different strategies
# - Intent-aware processor declarations (Transform vs Analyze)
# - Metadata propagation and handling
# - Multiple collection patterns in a single DAG
# ============================================================================

strategy: work_queue
failure_strategy: fail_fast

executor_options:
  max_concurrency: 4
  timeout_seconds: 30

processors:
  # ========================================================================
  # ENTRY POINT: Text Input Processor
  # ========================================================================
  - id: "input_text"
    type: local
    processor: "change_text_case_upper"
    # Intent: Transform (modifies data flow)
    # This processor converts input text to uppercase

  # ========================================================================
  # PARALLEL ANALYSIS PROCESSORS
  # ========================================================================
  # These processors run in parallel on the uppercase text
  # Intent: Analyze (safe for parallel execution, produce side information)
  
  - id: "token_analysis"
    type: local
    processor: "token_counter"
    depends_on: ["input_text"]
    # Intent: Analyze - counts characters, words, lines
    # Output: JSON with analysis results

  - id: "word_frequency"
    type: local
    processor: "word_frequency_analyzer" 
    depends_on: ["input_text"]
    # Intent: Analyze - produces word frequency histogram
    # Output: JSON with word counts

  # ========================================================================
  # COLLECTOR 1: Metadata Merge Strategy
  # ========================================================================
  # Combines analysis results with primary text flow
  # This collector takes the original text as primary and adds analysis as metadata
  
  - id: "analysis_merger"
    type: local
    processor: "metadata_merge_collector"
    depends_on: ["input_text", "token_analysis", "word_frequency"]
    options:
      primary_source: "input_text"           # Main text flow continues
      metadata_sources: ["token_analysis", "word_frequency"]  # Analysis becomes metadata
    # Intent: Transform - modifies data flow by enriching with metadata
    # Output: Primary text + analysis results as metadata

  # ========================================================================
  # TRANSFORM PROCESSORS: Text Modifications
  # ========================================================================
  # These processors modify the data flowing through the pipeline
  # Intent: Transform (sequential execution required)

  - id: "add_prefix"
    type: local
    processor: "prefix_suffix_adder"
    depends_on: ["analysis_merger"]
    options:
      prefix: ">>> "
      suffix: ""
    # Intent: Transform - adds prefix to text
    # Receives enriched text with metadata from analysis_merger

  - id: "reverse_text"
    type: local
    processor: "reverse_text"
    depends_on: ["add_prefix"]
    # Intent: Transform - reverses the text
    # Sequential execution after prefix addition

  # ========================================================================
  # PARALLEL BRANCH: Alternative Processing Path
  # ========================================================================
  # Create an alternative processing branch for demonstration
  
  - id: "lowercase_branch"
    type: local
    processor: "change_text_case_lower"
    depends_on: ["input_text"]
    # Intent: Transform - creates lowercase version
    # Runs in parallel with analysis processors

  - id: "proper_case_branch"
    type: local
    processor: "change_text_case_proper"
    depends_on: ["input_text"]
    # Intent: Transform - creates proper case version
    # Another parallel branch

  # ========================================================================
  # COLLECTOR 2: Concatenate Strategy
  # ========================================================================
  # Combines multiple text variations into a single output
  
  - id: "text_variations_combiner"
    type: local
    processor: "concatenate_collector"
    depends_on: ["lowercase_branch", "proper_case_branch"]
    options:
      separator: " | "
    # Intent: Transform - combines multiple text variations
    # Output: "hello world | Hello World"

  # ========================================================================
  # COLLECTOR 3: JSON Merge Strategy  
  # ========================================================================
  # Demonstrates JSON merging with conflict resolution
  # First, create some JSON outputs to merge
  
  - id: "json_analysis_1"
    type: local
    processor: "token_counter"
    depends_on: ["lowercase_branch"]
    # Creates JSON analysis of lowercase text

  - id: "json_analysis_2" 
    type: local
    processor: "word_frequency_analyzer"
    depends_on: ["proper_case_branch"]
    # Creates JSON analysis of proper case text

  - id: "json_merger"
    type: local
    processor: "json_merge_collector"
    depends_on: ["json_analysis_1", "json_analysis_2"]
    options:
      merge_arrays: true
      conflict_resolution: "merge"  # Options: take_first, take_last, merge, error
    # Intent: Transform - intelligently merges JSON outputs
    # Handles conflicts and combines analysis results

  # ========================================================================
  # COLLECTOR 4: First Available Strategy
  # ========================================================================
  # Demonstrates fallback behavior - takes first successful result
  
  - id: "fallback_collector"
    type: local
    processor: "first_available_collector"
    depends_on: ["reverse_text", "text_variations_combiner"]
    # Intent: Transform - provides fallback/redundancy
    # Takes whichever dependency completes successfully first
    # Useful for fault tolerance and performance optimization

  # ========================================================================
  # FINAL OUTPUT: Demonstrate Multiple Collection Results
  # ========================================================================
  # Final processor that could use any of the collector outputs
  
  - id: "final_output"
    type: local
    processor: "prefix_suffix_adder"
    depends_on: ["fallback_collector", "json_merger"]
    options:
      prefix: "[FINAL] "
      suffix: " [END]"
    # Intent: Transform - final output formatting
    # Note: This processor has multiple dependencies, so the work queue executor
    # will automatically insert a FirstAvailableCollector unless we specify
    # a collection_strategy (legacy approach) or use explicit collectors (new approach)

# ============================================================================
# EXECUTION FLOW SUMMARY:
# ============================================================================
#
# 1. INPUT: "hello world"
#    └─> input_text (uppercase) -> "HELLO WORLD"
#
# 2. PARALLEL ANALYSIS PHASE:
#    ├─> token_analysis -> {"char_count": 11, "word_count": 2, "line_count": 1}
#    ├─> word_frequency -> {"hello": 1, "world": 1}
#    ├─> lowercase_branch -> "hello world"
#    └─> proper_case_branch -> "Hello World"
#
# 3. COLLECTION PHASE:
#    ├─> analysis_merger (metadata merge) -> "HELLO WORLD" + metadata
#    ├─> text_variations_combiner (concatenate) -> "hello world | Hello World"
#    └─> json_merger (JSON merge) -> Combined analysis JSON
#
# 4. TRANSFORM PHASE:
#    ├─> add_prefix -> ">>> HELLO WORLD" + metadata
#    └─> reverse_text -> "DLROW OLLEH >>>" + metadata
#
# 5. FINAL COLLECTION:
#    └─> fallback_collector -> First of (reverse_text, text_variations_combiner)
#    └─> final_output -> "[FINAL] <result> [END]"
#
# ============================================================================
# ADR-12 FEATURES DEMONSTRATED:
# ============================================================================
#
# ✅ Intent Declaration:
#    - Transform processors: modify data flow (text case, prefix/suffix, reverse)
#    - Analyze processors: produce side information (token counter, word frequency)
#    - Collector processors: combine multiple inputs (all collector types)
#
# ✅ Metadata Propagation:
#    - analysis_merger enriches text with analysis metadata
#    - Metadata flows through subsequent transform processors
#
# ✅ Explicit Collection Strategies:
#    - metadata_merge_collector: Primary + secondary as metadata
#    - concatenate_collector: Combine with separator
#    - json_merge_collector: Smart JSON merging with conflict resolution
#    - first_available_collector: Fallback/redundancy pattern
#
# ✅ Hybrid Execution Model:
#    - Analyze processors can run in parallel safely
#    - Transform processors run sequentially to maintain data flow integrity
#    - Collectors handle multiple dependency coordination
#
# ✅ Backward Compatibility:
#    - Can mix with legacy collection_strategy approach if needed
#    - All existing processor types continue to work
#
# ============================================================================



workflows:
  - id: upper-case-and-word-count
    processors:
      - id: up-case
        processor: ChangeTextCaseUpper
        depends_on: []
      - id: word-count
        processor: WordFrequencyAnalyzer
        depends_on: [up-case]
  - id: title-case-with-prefix
    processors:
      - id: title-case
        processor: ChangeTextCaseTitle
        depends_on: []
      - id: add-prefix
        processor: PrefixSuffixAdder
        depends_on: [title-case]
        options:
          prefix: ">>> "
  - id: full-smash
    processors:
      - id: up-case
        processor: ChangeTextCaseUpper
        depends_on: []
      - id: word-count
        processor: WordFrequencyAnalyzer
        depends_on: [up-case]
      - id: token-counter
        processor: TokenCounter
        depends_on: [up-case]
      - id: add-prefix
        processor: PrefixSuffixAdder
        depends_on: [word-count, token-counter]
